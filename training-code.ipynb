{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T02:01:32.682815Z",
     "iopub.status.busy": "2023-05-25T02:01:32.681928Z",
     "iopub.status.idle": "2023-05-25T02:01:46.505613Z",
     "shell.execute_reply": "2023-05-25T02:01:46.504132Z",
     "shell.execute_reply.started": "2023-05-25T02:01:32.682757Z"
    },
    "id": "7m0rEjp7Ex4G",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T02:01:46.509978Z",
     "iopub.status.busy": "2023-05-25T02:01:46.509172Z",
     "iopub.status.idle": "2023-05-25T02:01:59.246544Z",
     "shell.execute_reply": "2023-05-25T02:01:59.245620Z",
     "shell.execute_reply.started": "2023-05-25T02:01:46.509939Z"
    },
    "id": "BvAEHzZ5c3_1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn.functional as F\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd7iKbfRPNXs"
   },
   "source": [
    "# GPT2 with Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugqA8sTyorE7"
   },
   "source": [
    "### PIPELINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T02:01:59.248576Z",
     "iopub.status.busy": "2023-05-25T02:01:59.248261Z",
     "iopub.status.idle": "2023-05-25T02:02:03.897882Z",
     "shell.execute_reply": "2023-05-25T02:02:03.896727Z",
     "shell.execute_reply.started": "2023-05-25T02:01:59.248551Z"
    },
    "id": "VA0fsB0kkO3P"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Mahmoud-Hesham99/Arabic-Lyrics-Generation/main/arabicLyrics.csv')\n",
    "df = df.replace(\"غيرمعروف\",np.NAN)\n",
    "df = df.replace(\"غير معروف\",np.NAN)\n",
    "df = df.drop(['SongTitle','SongWriter','Composer','SingerNationality'],axis=1)\n",
    "grouped_df = df.groupby('songID')['Lyrics'].apply('\\n'.join).reset_index()\n",
    "temp = pd.merge(grouped_df,df.drop([\"LyricsOrder\",\"Lyrics\"],axis=1), on=\"songID\")\n",
    "temp = temp.drop_duplicates(keep=\"first\").reset_index().drop([\"songID\",\"index\"],axis=1).reset_index()\n",
    "temp = temp.rename({\"index\":\"songID\"},axis=\"columns\")\n",
    "df = temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T02:02:03.899924Z",
     "iopub.status.busy": "2023-05-25T02:02:03.899284Z",
     "iopub.status.idle": "2023-05-25T02:02:03.905617Z",
     "shell.execute_reply": "2023-05-25T02:02:03.904220Z",
     "shell.execute_reply.started": "2023-05-25T02:02:03.899888Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class for the song lyrics\n",
    "class SongLyrics(Dataset):\n",
    "    \n",
    "    def __init__(self, input_df, gpt2_type=\"gpt2\"):\n",
    "        # Initialize the GPT-2 tokenizer\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
    "        self.lyrics = []\n",
    "\n",
    "        # Encode lyrics and store them in a list\n",
    "        for row in input_df:\n",
    "            temp = self.tokenizer.encode(f\"{row[:1024]}\")\n",
    "            # if length of encoding less than 1000 add it\n",
    "            if len(temp) <= 1000:\n",
    "                self.lyrics.append(torch.tensor(temp))\n",
    "        \n",
    "        # Store the number of lyrics in the dataset\n",
    "        self.lyrics_count = len(self.lyrics)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.lyrics_count\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.lyrics[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T02:02:03.922142Z",
     "iopub.status.busy": "2023-05-25T02:02:03.921853Z",
     "iopub.status.idle": "2023-05-25T02:02:03.931668Z",
     "shell.execute_reply": "2023-05-25T02:02:03.930714Z",
     "shell.execute_reply.started": "2023-05-25T02:02:03.922110Z"
    },
    "id": "Maf_wuBuJl2n"
   },
   "outputs": [],
   "source": [
    "#Accumulated batch size (since GPT2 is so big)\n",
    "# Utility function to pack tensors based on a maximum sequence length\n",
    "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
    "    if packed_tensor is None:\n",
    "        return new_tensor, True, None\n",
    "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
    "        return packed_tensor, False, new_tensor\n",
    "    else:\n",
    "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
    "        return packed_tensor, True, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training the model\n",
    "def train(\n",
    "    dataset, model, tokenizer,\n",
    "    batch_size=16, epochs=20, lr=2e-5,\n",
    "    max_seq_len=400, warmup_steps=200,\n",
    "    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n",
    "    test_mode=False, save_model_on_epoch=False,\n",
    "):\n",
    "    # Set up training parameters\n",
    "    acc_steps = 100\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = model.cuda()\n",
    "    model.train()\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    loss = 0\n",
    "    accumulating_batch_count = 0\n",
    "    input_tensor = None\n",
    "\n",
    "    # Iterate over epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Training epoch {epoch}\")\n",
    "        print(loss)\n",
    "        \n",
    "        # Iterate over batches in the dataloader\n",
    "        for idx, entry in tqdm(enumerate(train_dataloader)):\n",
    "            # Pack the input tensors based on the maximum sequence length\n",
    "            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
    "\n",
    "            if carry_on and idx != len(train_dataloader) - 1:\n",
    "                continue\n",
    "\n",
    "            input_tensor = input_tensor.to(device)\n",
    "            outputs = model(input_tensor, labels=input_tensor)\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "\n",
    "            if (accumulating_batch_count % batch_size) == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                model.zero_grad()\n",
    "\n",
    "            accumulating_batch_count += 1\n",
    "            input_tensor = None\n",
    "        \n",
    "        # Save the model at each epoch if specified\n",
    "        if save_model_on_epoch:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
    "            )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process songs by dialect\n",
    "for name in temp[\"SongDialect\"].unique():\n",
    "    # Filter songs based on dialect\n",
    "    df = temp[temp[\"SongDialect\"]==name]\n",
    "    \n",
    "    # Preprocess the lyrics (e.g., remove punctuation)\n",
    "    df['Lyrics'] = df['Lyrics'].apply(remove_punctuation)\n",
    "    \n",
    "    # Create a small test set for evaluation\n",
    "    test_set = df.sample(n=10, random_state=32)\n",
    "    df = df.loc[~df.index.isin(test_set.index)]\n",
    "\n",
    "    # Reset the indexes\n",
    "    test_set = test_set.reset_index()\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Store the last 20 words in a separate column for evaluation\n",
    "    test_set['True_end_lyrics'] = test_set['Lyrics'].str.split().str[-20:].apply(' '.join)\n",
    "    test_set['Lyrics'] = test_set['Lyrics'].str.split().str[:-20].apply(' '.join)\n",
    "    \n",
    "    # Create the dataset using the preprocessed lyrics and GPT-2 tokenizer\n",
    "    dataset = SongLyrics(df['Lyrics'], gpt2_type=\"gpt2\")\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    \n",
    "    # Create or load the GPT-2 model\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    \n",
    "    # Fine-tune the GPT-2 model on the lyrics dataset\n",
    "    model = train(dataset, model, tokenizer)\n",
    "    \n",
    "    # Save the trained model for future use\n",
    "    torch.save(model, f'/kaggle/working/model_{name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T23:23:58.327552Z",
     "iopub.status.busy": "2023-05-24T23:23:58.327202Z",
     "iopub.status.idle": "2023-05-24T23:23:59.503591Z",
     "shell.execute_reply": "2023-05-24T23:23:59.502276Z",
     "shell.execute_reply.started": "2023-05-24T23:23:58.327524Z"
    },
    "id": "gvk9JcukKKq1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GPT2_final",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
